import gdown
import zipfile
import os
import pandas as pd
from pathlib import Path

def download_and_extract_kaggle_data(
    url: str = 'https://drive.google.com/uc?id=1QDHZrqQ8gbNW18Flxs5RCsC_tv7hxfeH',
    output_path: str = 'data/raw/sentiment_kaggle.zip',
    extract_dir: str = 'data/raw/sentiment_kaggle',
    parquet_output: str = 'data/raw/sentiment_kaggle.parquet'
):
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    print(f"â¬‡ï¸ Downloading Kaggle sentiment140 dataset from Google Drive...")
    gdown.download(url, output_path, quiet=False)

    print(f"ğŸ“¦ Extracting to: {extract_dir}")
    with zipfile.ZipFile(output_path, "r") as zip_ref:
        zip_ref.extractall(extract_dir)

    os.remove(output_path)
    print("âœ… Download and extraction complete.")

    # Find CSV file in the extracted directory
    csv_files = [f for f in os.listdir(extract_dir) if f.endswith(".csv")]
    if not csv_files:
        raise FileNotFoundError("âŒ No CSV file found in the extracted directory.")

    csv_path = os.path.join(extract_dir, csv_files[0])
    print(f"ğŸ“„ Found CSV file: {csv_path}")

    print("ğŸ“Š Loading CSV into DataFrame...")
    df = pd.read_csv(csv_path, encoding='ISO-8859-1', header=None)

    # Save to Parquet
    Path(os.path.dirname(parquet_output)).mkdir(parents=True, exist_ok=True)
    df.to_parquet(parquet_output, index=False)
    print(f"âœ… Saved as Parquet to: {parquet_output}")

    # Remove the original CSV file
    os.remove(csv_path)
    print(f"ğŸ—‘ï¸ Removed original CSV: {csv_path}")

if __name__ == "__main__":
    download_and_extract_kaggle_data()
